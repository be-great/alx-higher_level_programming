# 0x14. JavaScript - Web scraping

Web scraping with JavaScript typically involves extracting data from websites by interacting with their HTML and possibly their APIs. Here’s a broad overview of how you can accomplish this using JavaScript, along with some common tools and techniques:
## 1. Using Node.js with Libraries

In the context of server-side JavaScript, you can use Node.js along with several popular libraries to perform web scraping:
### a. Axios

    axios is a promise-based HTTP client for Node.js that you can use to make requests to websites.
```js
const axios = require('axios');

axios.get('https://example.com')
  .then(response => {
    console.log(response.data); // This will log the HTML of the page
  })
  .catch(error => {
    console.error('Error fetching the page:', error);
  });
```
### b. Cheerio

    cheerio is a fast, flexible, and lean implementation of jQuery designed for the server. It allows you to parse HTML and manipulate the DOM.
```js
const cheerio = require('cheerio');
const axios = require('axios');

axios.get('https://example.com')
  .then(response => {
    const $ = cheerio.load(response.data);
    const title = $('title').text();
    console.log('Title:', title);
  })
  .catch(error => {
    console.error('Error fetching the page:', error);
  });
```
### c. Puppeteer

    puppeteer is a Node library that provides a high-level API to control headless Chrome or Chromium. It’s particularly useful for scraping dynamic content generated by JavaScript.

```js
const puppeteer = require('puppeteer');

(async () => {
  const browser = await puppeteer.launch();
  const page = await browser.newPage();
  await page.goto('https://example.com');
  const content = await page.content();
  console.log(content); // The HTML of the page

  await browser.close();
})();
```
## 2. Using JavaScript in the Browser

For client-side JavaScript, you can use the browser's built-in capabilities to extract data:
### a. Fetch API

    The Fetch API provides a modern way to make HTTP requests in the browser.

```js
fetch('https://example.com')
  .then(response => response.text())
  .then(data => {
    console.log(data); // This will log the HTML of the page
  })
  .catch(error => {
    console.error('Error fetching the page:', error);
  });
```
### b. DOM Manipulation

    Once you have fetched the HTML content, you can use DOM manipulation methods to extract information.

```js
document.addEventListener('DOMContentLoaded', () => {
  const title = document.querySelector('title').innerText;
  console.log('Title:', title);
});
```

## 3. Ethical Considerations

    Respect robots.txt: Always check the robots.txt file of a website to see if scraping is allowed. This file is located at https://example.com/robots.txt.

    Avoid Overloading Servers: Implement rate limiting to avoid sending too many requests in a short period of time.

    Check Legal Restrictions: Ensure that scraping does not violate the website's terms of service or legal guidelines.

## 4. Example Use Case

    Suppose you want to scrape headlines from a news website. Here’s how you might use axios, cheerio, and puppeteer for this purpose:

    Using axios and cheerio:

```js
const axios = require('axios');
const cheerio = require('cheerio');

axios.get('https://news.ycombinator.com/')
  .then(response => {
    const $ = cheerio.load(response.data);
    $('a.storylink').each((index, element) => {
      console.log($(element).text());
    });
  })
  .catch(error => {
    console.error('Error fetching the page:', error);
  });
```
Using puppeteer for dynamic content:

```js
const puppeteer = require('puppeteer');

(async () => {
  const browser = await puppeteer.launch();
  const page = await browser.newPage();
  await page.goto('https://news.ycombinator.com/');

  const headlines = await page.evaluate(() => {
    return Array.from(document.querySelectorAll('a.storylink')).map(link => link.textContent);
  });

  console.log(headlines);

  await browser.close();
})();
```